{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning [Phi-1.5 model](https://huggingface.co/microsoft/phi-1_5) on the collected Kotlin dataset"
      ],
      "metadata": {
        "id": "kfDcm4m2Uavl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install accelerate transformers einops datasets peft bitsandbytes fuzzywuzzy"
      ],
      "metadata": {
        "id": "sVj5q1HkTGdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling, BitsAndBytesConfig, QuantoConfig\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import json\n",
        "from typing import List, Tuple\n",
        "from torch import nn\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from fuzzywuzzy import fuzz\n",
        "import re"
      ],
      "metadata": {
        "id": "SXMYSBJzPmwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KotlinDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, max_length):\n",
        "        with open(file_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        self.examples = [json.loads(line) for line in lines]\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        entry = self.examples[idx]\n",
        "        # Concatenate 'input' and 'gt' fields before passing to the tokenizer\n",
        "        context = entry['input'].split('<EOL>')[-5:]  # Use the last 5 lines\n",
        "        context = '<EOL>'.join(context).strip()\n",
        "        concatenated_input = context + entry['gt']\n",
        "        encoding = self.tokenizer(concatenated_input,\n",
        "                                  max_length=self.max_length,\n",
        "                                  truncation=True,\n",
        "                                  padding='max_length',\n",
        "                                  return_tensors='pt')\n",
        "        input_ids = encoding['input_ids'].squeeze(0)\n",
        "        labels = input_ids.clone()\n",
        "\n",
        "        return {'input_ids': torch.tensor(input_ids), 'labels': labels}"
      ],
      "metadata": {
        "id": "P2lwb05WPja_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_special_tokens(path: str) -> List[str]:\n",
        "\n",
        "    \"\"\"\n",
        "    Load special tokens from a JSON file and format them into a list.\n",
        "    \"\"\"\n",
        "\n",
        "    with open(path, \"r\") as file:\n",
        "        literals = json.load(file)\n",
        "    tokens = [\"<STR_LIT>\", \"<NUM_LIT>\", \"<CHAR_LIT>\"]\n",
        "    tokens.extend(f\"<STR_LIT:{lit}>\" for lit in literals[\"str\"])\n",
        "    tokens.extend(f\"<NUM_LIT:{lit}>\" for lit in literals[\"num\"])\n",
        "    tokens.extend(f\"<CHAR_LIT:{lit}>\" for lit in literals[\"char\"])\n",
        "\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def load_model(model_name: str,\n",
        "               special_tokens_path: str,\n",
        "               bnb_config) -> Tuple[AutoTokenizer, nn.Module]:\n",
        "\n",
        "    \"\"\"\n",
        "    Load a pretrained tokenizer and model from Hugging Face, and add special tokens.\n",
        "    \"\"\"\n",
        "\n",
        "    special_tokens = load_special_tokens(special_tokens_path)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "                                              additional_special_tokens=special_tokens)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    model.resize_token_embeddings(len(tokenizer))  # Important to resize model token embeddings\n",
        "\n",
        "    return tokenizer, model"
      ],
      "metadata": {
        "id": "UVSc2FE7QU3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "model_name = \"microsoft/phi-1.5\"\n",
        "special_tokens_path = \"literals.json\"\n",
        "tokenizer, model = load_model(model_name, special_tokens_path, bnb_config)"
      ],
      "metadata": {
        "id": "ajOUoxViR4Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"dense\", \"fc2\",\"q_proj\",\"k_proj\",\"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heABy75WUoPA",
        "outputId": "c67a55c0-418a-460c-b1fd-adecc32745f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 10,223,616 || all params: 1,425,241,318 || trainable%: 0.7173252607036754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the dataset\n",
        "dataset = KotlinDataset('/content/kotlin_code_train.json', tokenizer, 256)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./kotlin_code_completion',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained('./kotlin_code_completion_model')\n",
        "tokenizer.save_pretrained('./kotlin_code_completion_model')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p4dNFlOERPiB",
        "outputId": "676f7eb6-b44f-4dea-fc8e-9ba30b091669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-d221ba6f0800>:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {'input_ids': torch.tensor(input_ids), 'labels': labels}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1413' max='1413' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1413/1413 08:34, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>12.076400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>10.173700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>8.892400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>8.268900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>7.758300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>7.271600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>6.897100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>6.679200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>5.951600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>5.243500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>5.212000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>5.144400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>5.079700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>4.993400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>4.957600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>5.297700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>4.923300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>4.803500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>4.892300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>4.832200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>4.790500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>4.880400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>4.841600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>4.854400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>4.721900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>4.658100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>4.743500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>4.858800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>4.760100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>4.680600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>4.747700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>4.744300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>4.671600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>4.651400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>4.676300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>4.701400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>4.609300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>4.794500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>4.571100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>4.677800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>4.656500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>4.669700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>4.579400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>4.722200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>4.633800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>4.720400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>4.729000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>4.670600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>4.612200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>4.641900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>4.617100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>4.596200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>4.532000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>4.631800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>4.729900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>4.648900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>4.636400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>4.675900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>4.598100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>4.678500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>4.606700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>4.697500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>4.604800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>4.472400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>4.582800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>4.476800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>4.538600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>4.535700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>4.608500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>4.555700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>4.461600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>4.504200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>4.586200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>4.550600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>4.617600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>4.697400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>4.587300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>4.458000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>4.582500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>4.604700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>4.574800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>4.530800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>4.426400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>4.518200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>4.479200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>4.602100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>4.565500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>4.491600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>4.600800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>4.603900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>4.455000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>4.504900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>4.589600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>4.456400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>4.596300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>4.526100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>4.538800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>4.455100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>4.598400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>4.545700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>4.632100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>4.615800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>4.533600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>4.459000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>4.522500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>4.520600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>4.498000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>4.479200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>4.481200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>4.513700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>4.641300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>4.616900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>4.525100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>4.558600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>4.461800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>4.526800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>4.523100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>4.547600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>4.417100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>4.505700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>4.423800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>4.354700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>4.523100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>4.488100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>4.531500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>4.539000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>4.469200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>4.523400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>4.491500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>4.435600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>4.502800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>4.597800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>4.583300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>4.473600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>4.617500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>4.535800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>4.557800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>4.530100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>4.442300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>4.465600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>4.460500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:168: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-d221ba6f0800>:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {'input_ids': torch.tensor(input_ids), 'labels': labels}\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:168: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-d221ba6f0800>:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {'input_ids': torch.tensor(input_ids), 'labels': labels}\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:168: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./kotlin_code_completion_model/tokenizer_config.json',\n",
              " './kotlin_code_completion_model/special_tokens_map.json',\n",
              " './kotlin_code_completion_model/vocab.json',\n",
              " './kotlin_code_completion_model/merges.txt',\n",
              " './kotlin_code_completion_model/added_tokens.json',\n",
              " './kotlin_code_completion_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "\n",
        "Evaluate the fine-tuned model on the same Python CodeXGLUE test set and Kotlin test set"
      ],
      "metadata": {
        "id": "mtWzKDVKbn0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_line(code: str, tokenizer: AutoTokenizer,\n",
        "                      model: nn.Module, device: str = 'cuda') -> str:\n",
        "\n",
        "    \"\"\"\n",
        "    Predict the next line of code given an input sequence of code.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    inputs = tokenizer.encode(code, return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(inputs, max_length=512, num_return_sequences=1)\n",
        "    predicted_code = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return predicted_code\n",
        "\n",
        "\n",
        "def read_and_predict(json_file: str, tokenizer: AutoTokenizer,\n",
        "                     model: torch.nn.Module, device: str = 'cuda') -> None:\n",
        "\n",
        "    \"\"\"\n",
        "    Read JSON file containing code inputs, and predict the next line for each input.\n",
        "    \"\"\"\n",
        "\n",
        "    outputs = []\n",
        "    with open(json_file, 'r') as file:\n",
        "        for n, line in enumerate(file):\n",
        "            try:\n",
        "                json_object = json.loads(line)\n",
        "                input_lines = json_object['input'].split('<EOL>')\n",
        "                # Keep only the last 5 lines\n",
        "                if len(input_lines) > 5:\n",
        "                    input_lines = input_lines[-5:]\n",
        "                input_code = '<EOL>'.join(input_lines) + '<EOL>'\n",
        "                num_lines = len(input_code.split('<EOL>')) - 1\n",
        "                predicted_line = predict_next_line(input_code, tokenizer, model, device)\n",
        "                predicted_line = predicted_line.replace('\\n', '<EOL>')\n",
        "                print(predicted_line.split('<EOL>'))\n",
        "                print(predicted_line.split('<EOL>')[num_lines])\n",
        "                outputs.append(predicted_line.split('<EOL>')[num_lines])\n",
        "                print(n)\n",
        "\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error reading JSON: {e}\")\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "gUmZEfqdb0es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def post_process(code: str) -> str:\n",
        "\n",
        "    \"\"\" Converting special symbols in a code string to their respective\n",
        "    literals or removing them \"\"\"\n",
        "\n",
        "    code = code.replace(\"<NUM_LIT>\", \"0\").replace(\"<STR_LIT>\", \"\").replace(\"<CHAR_LIT>\", \"\")\n",
        "    pattern = re.compile(r\"<(STR|NUM|CHAR)_LIT:(.*?)>\", re.S)\n",
        "    lits = re.findall(pattern, code)\n",
        "    for lit in lits:\n",
        "        code = code.replace(f\"<{lit[0]}_LIT:{lit[1]}>\", lit[1])\n",
        "    return code\n",
        "\n",
        "\n",
        "def evaluate(answers_path: str, predictions_path: str) -> None:\n",
        "\n",
        "    \"\"\" Evaluating predictions against ground truth answers,\n",
        "    computing exact match (EM) and edit similarity metrics \"\"\"\n",
        "\n",
        "    data = []\n",
        "    with open(answers_path, 'r') as i_file:\n",
        "        for line in i_file:\n",
        "            try:\n",
        "                data.append(json.loads(line))\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error decoding JSON: {e}\")\n",
        "                continue\n",
        "\n",
        "    with open(predictions_path, \"r\") as f:\n",
        "        gts = f.readlines()\n",
        "\n",
        "    assert len(data) == len(gts), f\"Samples of predictions and answers are not equal, {len(data)}: {len(gts)}\"\n",
        "\n",
        "    total = len(gts)\n",
        "    EM = 0.0\n",
        "    edit_sim = 0.0\n",
        "    for i, (gt, pred) in enumerate(zip(data, gts)):\n",
        "        try:\n",
        "            pred = post_process(pred.strip())\n",
        "            gt = post_process(gt[\"gt\"])\n",
        "            edit_sim += fuzz.ratio(pred, gt)\n",
        "            if pred.split() == gt.split():\n",
        "                EM += 1\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding JSON on line {i + 1}: {gt}\")\n",
        "            print(e)\n",
        "            continue  # Skip this line or handle it as needed\n",
        "\n",
        "    edit_similarity = round(edit_sim / total, 2) if total else 0\n",
        "    exact_match = round((EM / total) * 100, 2) if total else 0\n",
        "    print(f\"Edit sim: {edit_similarity}, EM: {exact_match}\")\n"
      ],
      "metadata": {
        "id": "m5drL5kvcJiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation on Python test set"
      ],
      "metadata": {
        "id": "WCGwXT0BfBfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python_outputs = read_and_predict(json_file='/content/CodeXGLUE_test_processed.json',\n",
        "                                  tokenizer=tokenizer,\n",
        "                                  model=model)"
      ],
      "metadata": {
        "id": "Wm-2Tr6OeEJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('predictions_finetuned_python.txt', 'w') as fp:\n",
        "    for item in python_outputs:\n",
        "        fp.write(item)\n",
        "        fp.write('\\n')"
      ],
      "metadata": {
        "id": "Q_78nlBCeZuo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation on Kotlin test set"
      ],
      "metadata": {
        "id": "oXsZsSlffFdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kotlin_outputs = read_and_predict(json_file='/content/kotlin_code_test.json',\n",
        "                                  tokenizer=tokenizer,\n",
        "                                  model=model)"
      ],
      "metadata": {
        "id": "xnTiJO7-eZ2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('predictions_finetuned_kotlin.txt', 'w') as fp:\n",
        "    for item in kotlin_outputs:\n",
        "        fp.write(item)\n",
        "        fp.write('\\n')"
      ],
      "metadata": {
        "id": "442nJVRyf3kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the performance"
      ],
      "metadata": {
        "id": "88B9yMbGfVQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CodeXGLUE Python"
      ],
      "metadata": {
        "id": "ksSsqrZ4gPHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate('/content/CodeXGLUE_test_answers.json',\n",
        "         '/content/predictions_finetuned_python.txt')"
      ],
      "metadata": {
        "id": "bHszlmxkcbs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6763483b-cc16-4617-cca3-acbdeccc19c5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edit sim: 8.16, EM: 3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kotlin"
      ],
      "metadata": {
        "id": "d8dYtnH7gRbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate('/content/kotlin_code_answers.json',\n",
        "         '/content/predictions_finetuned_kotlin.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaNXXuC3gOeR",
        "outputId": "fc51220f-dcdb-4baa-f496-bfb4e5787fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edit sim: 16.05, EM: 10.0\n"
          ]
        }
      ]
    }
  ]
}